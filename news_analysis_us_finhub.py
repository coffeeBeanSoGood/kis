# news_analysis_us_rklb_portfolio.py (RKLB í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” ë²„ì „)
from openai import OpenAI
import requests
from datetime import datetime, timedelta
from dotenv import load_dotenv
import os
import re
import json
import logging
import hashlib
import pickle
import time

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

def set_logger(external_logger):
    """ì™¸ë¶€ì—ì„œ ë¡œê±°ë¥¼ ì„¤ì •í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜"""
    global logger
    logger = external_logger

try:
    import auto_economic_calendar
    auto_economic_calendar.set_logger(logger)  # ë¡œê±° ì „ë‹¬
    ECONOMIC_CALENDAR_AVAILABLE = True
    logger.info("ğŸ“… ìë™ ê²½ì œ ìº˜ë¦°ë” ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    ECONOMIC_CALENDAR_AVAILABLE = False
    logger.warning(f"âš ï¸ ìë™ ê²½ì œ ìº˜ë¦°ë” ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
    logger.warning("ê¸°ì¡´ í‚¤ì›Œë“œ ì‹œìŠ¤í…œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.")

# GPT ë¶„ì„ ìºì‹œ ê´€ë ¨ í•¨ìˆ˜ë“¤
def create_stocks_hash(stocks_list):
    try:
        stock_codes = sorted([s.get('ticker') or s.get('StockCode') for s in stocks_list])
        hash_string = '_'.join(stock_codes)
        return hashlib.md5(hash_string.encode()).hexdigest()[:8]
    except Exception as e:
        logger.error(f"Hash ìƒì„± ì˜¤ë¥˜: {e}")
        return "default"

def get_cached_gpt_analysis(cache_key, cache_minutes=240):  # 4ì‹œê°„ ìºì‹œ
    try:
        cache_dir = "gpt_cache"
        os.makedirs(cache_dir, exist_ok=True)
        cache_file = os.path.join(cache_dir, f"gpt_analysis_{cache_key}.pkl")

        if os.path.exists(cache_file):
            with open(cache_file, 'rb') as f:
                cache_data = pickle.load(f)
            age = datetime.now() - cache_data['timestamp']
            if age < timedelta(minutes=cache_minutes):
                logger.info(f"ğŸ“° GPT ë¶„ì„ ìºì‹œ ì‚¬ìš© (ë‚˜ì´: {age.total_seconds()/60:.1f}ë¶„)")
                return cache_data['analysis']
            else:
                logger.info(f"ğŸ“° GPT ë¶„ì„ ìºì‹œ ë§Œë£Œ ({age.total_seconds()/60:.1f}ë¶„ ê²½ê³¼)")
                os.remove(cache_file)  # ë§Œë£Œëœ ìºì‹œ ì‚­ì œ
    except Exception as e:
        logger.error(f"ìºì‹œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
    return None

def cache_gpt_analysis(cache_key, analysis):
    try:
        cache_dir = "gpt_cache"
        os.makedirs(cache_dir, exist_ok=True)
        cache_file = os.path.join(cache_dir, f"gpt_analysis_{cache_key}.pkl")
        with open(cache_file, 'wb') as f:
            pickle.dump({"timestamp": datetime.now(), "analysis": analysis}, f)
        logger.info(f"ğŸ“° GPT ë¶„ì„ ê²°ê³¼ ìºì‹œ ì €ì¥ ì™„ë£Œ (í‚¤: {cache_key})")
    except Exception as e:
        logger.error(f"ìºì‹œ ì €ì¥ ì˜¤ë¥˜: {e}")

# ğŸ”¥ RKLB í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” ë‰´ìŠ¤ ì˜í–¥ í‚¤ì›Œë“œ ì‹œìŠ¤í…œ
def get_impact_keywords():
    """RKLB í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” + ìë™ ê²½ì œ ìº˜ë¦°ë” ì—°ë™ í‚¤ì›Œë“œ ì‹œìŠ¤í…œ"""
    
    # ğŸ”¥ ê¸°ì¡´ RKLB í¬íŠ¸í´ë¦¬ì˜¤ íŠ¹í™” í‚¤ì›Œë“œ (ê·¸ëŒ€ë¡œ ìœ ì§€)
    impact_keywords = [
        # ğŸ“Š ê¸°ë³¸ ì¬ë¬´/ì‹¤ì  ê´€ë ¨
        'earnings', 'revenue', 'profit', 'loss', 'guidance', 'forecast', 'outlook',
        'sales', 'income', 'margin', 'eps', 'beat', 'miss', 'estimate', 'consensus',
        'quarterly', 'annual', 'report', 'results', 'performance', 'growth',
        
        # ğŸ“ˆ ì£¼ê°€/íˆ¬ì ê´€ë ¨  
        'upgrade', 'downgrade', 'rating', 'target', 'price target', 'buy', 'sell', 'hold',
        'outperform', 'underperform', 'overweight', 'underweight', 'recommendation',
        'analyst', 'research', 'coverage', 'initiate', 'maintain', 'raise', 'lower',
        
        # ğŸ¤ ê¸°ì—… í™œë™/ê±°ë˜
        'acquisition', 'merger', 'buyback', 'split', 'dividend', 'spinoff',
        'partnership', 'collaboration', 'joint venture', 'alliance', 'agreement',
        'contract', 'deal', 'transaction', 'investment', 'funding', 'raise',
        'IPO', 'SPAC', 'listing', 'offering', 'warrant', 'convertible',
        
        # ğŸ‘¥ ê²½ì˜ì§„/ë¦¬ë”ì‹­
        'CEO', 'CFO', 'CTO', 'president', 'chairman', 'executive', 'management',
        'hire', 'resign', 'retire', 'appoint', 'promote', 'leadership',
        'board', 'director', 'succession', 'change', 'transition',
        
        # âš–ï¸ ê·œì œ/ë²•ë¥ 
        'lawsuit', 'regulatory', 'approval', 'patent', 'license', 'compliance',
        'investigation', 'settlement', 'fine', 'violation', 'FDA', 'SEC', 'NRC',
        'DOE', 'NNSA', 'EPA', 'FTC', 'DOJ', 'court', 'legal', 'litigation',
        
        # ğŸ”¬ ê¸°ìˆ /í˜ì‹  (ì¼ë°˜)
        'breakthrough', 'technology', 'innovation', 'research', 'development',
        'clinical', 'trial', 'study', 'product', 'launch', 'release',
        'patent', 'intellectual property', 'R&D', 'prototype', 'testing',
        
        # ğŸ¯ CCJ (ì¹´ë©”ì½” - ìš°ë¼ëŠ„ ë§ˆì´ë‹) íŠ¹í™” í‚¤ì›Œë“œ
        'uranium', 'yellowcake', 'nuclear fuel', 'mining', 'Kazakhstan', 'Canada',
        'Cigar Lake', 'McArthur River', 'Key Lake', 'Rabbit Lake', 'Smith Ranch',
        'fuel cycle', 'enrichment', 'conversion', 'UF6', 'U3O8',
        'nuclear power', 'reactor', 'utility', 'long term contract', 'spot price',
        'cameco', 'CCO', 'athabasca', 'mine', 'production', 'reserves',
        'geological', 'exploration', 'deposit', 'ore', 'grade', 'mill',
        'tailings', 'environmental', 'indigenous', 'community', 'royalty',
        
        # ğŸ­ BWXT (BWX Technologies - ì›ìë¡œ ê¸°ìˆ ) íŠ¹í™” í‚¤ì›Œë“œ
        'nuclear reactor', 'SMR', 'small modular reactor', 'naval reactor', 'TRISO',
        'microreactor', 'nuclear fuel', 'reactor pressure vessel', 'steam generator',
        'nuclear components', 'nuclear services', 'navy contract', 'DOE contract',
        'BWX Technologies', 'BWXT', 'nuclear manufacturing', 'reactor design',
        'fuel assembly', 'control rod', 'reactor core', 'nuclear island',
        'HALEU', 'enriched uranium', 'fuel fabrication', 'nuclear testing',
        'Virginia', 'Ohio', 'Cambridge', 'Lynchburg', 'Barberton',
        'defense', 'naval', 'submarine', 'aircraft carrier', 'propulsion',
        
        # â„ï¸ VRT (ë²„í‹°ë¸Œ - ë°ì´í„°ì„¼í„° ì¸í”„ë¼) íŠ¹í™” í‚¤ì›Œë“œ
        'data center', 'cooling', 'thermal management', 'UPS', 'power protection',
        'liquid cooling', 'immersion cooling', 'HVAC', 'infrastructure', 'edge computing',
        'hyperscale', 'colocation', 'cloud', 'AI infrastructure', 'GPU cooling',
        'vertiv', 'liebert', 'geist', 'avocent', 'trellis', 'smartaisle',
        'power distribution', 'PDU', 'battery', 'generator', 'chiller',
        'precision cooling', 'raised floor', 'rack', 'cabinet', 'monitoring',
        'energy efficiency', 'PUE', 'sustainability', 'green data center',
        'Microsoft', 'Amazon', 'Google', 'Meta', 'hyperscaler',
        
        # ğŸš€ RKLB (ë¡œì¼“ë© - ìš°ì£¼í•­ê³µ) íŠ¹í™” í‚¤ì›Œë“œ
        'rocket', 'space', 'satellite', 'launch', 'orbit', 'mission', 'payload',
        'spacecraft', 'aerospace', 'NASA', 'SpaceX', 'constellation', 'deployment',
        'electron', 'neutron', 'reusability', 'commercial space', 'defense',
        'rocket lab', 'RKLB', 'wallops', 'mahia', 'beck', 'photon',
        'kick stage', 'fairing', 'engine', 'rutherford', 'archimedes',
        'launch pad', 'range', 'trajectory', 'telemetry', 'recovery',
        'small satellite', 'cubesat', 'rideshare', 'dedicated launch',
        'space force', 'SDA', 'reconnaissance', 'communication satellite',
        
        # ğŸ’¼ ì‹œì¥/ê²½ìŸ ê´€ë ¨
        'market share', 'competition', 'competitor', 'rival', 'disruption',
        'expansion', 'growth', 'scale', 'capacity', 'demand', 'supply',
        'backlog', 'order', 'customer', 'client', 'win', 'award',
        'tender', 'bid', 'RFP', 'proposal', 'selection', 'preferred',
        
        # ğŸ’° ìê¸ˆ/íˆ¬ì ê´€ë ¨
        'debt', 'credit', 'loan', 'bond', 'equity', 'valuation',
        'cash', 'cash flow', 'working capital', 'capex', 'opex',
        'financing', 'refinancing', 'facility', 'line of credit',
        'institutional investor', 'fund', 'private equity', 'venture capital',
        
        # ğŸ“‰ ë¦¬ìŠ¤í¬/ë¶€ì •ì  í‚¤ì›Œë“œ
        'bankruptcy', 'default', 'restructure', 'layoff', 'closure', 'suspend',
        'recall', 'cyber attack', 'data breach', 'scandal', 'fraud',
        'accident', 'incident', 'failure', 'malfunction', 'outage',
        'delay', 'postpone', 'cancel', 'terminate', 'breach',
        
        # ğŸŒ ê¸€ë¡œë²Œ/ê±°ì‹œê²½ì œ
        'inflation', 'interest rate', 'fed', 'federal reserve', 'tariff', 'trade war',
        'recession', 'recovery', 'stimulus', 'policy', 'geopolitical',
        'sanctions', 'export control', 'national security', 'critical minerals',
        'supply chain', 'logistics', 'shortage', 'disruption',
        
        # ğŸ¯ ì„±ê³¼/ë§ˆì¼ìŠ¤í†¤
        'milestone', 'achievement', 'record', 'first', 'successful', 'completion',
        'delivery', 'deployment', 'operational', 'commercial', 'production',
        'commissioning', 'startup', 'ramp up', 'scale up', 'full capacity',
        'certification', 'qualification', 'validation', 'verification',
        
        # ğŸ”® ë¯¸ë˜/ì „ë§ í‚¤ì›Œë“œ
        'pipeline', 'roadmap', 'timeline', 'schedule', 'plan', 'strategy',
        'vision', 'potential', 'opportunity', 'challenge', 'risk',
        'outlook', 'projection', 'estimate', 'target', 'goal', 'objective',
        
        # ğŸ›ï¸ ì •ë¶€/ì •ì±… í‚¤ì›Œë“œ
        'government', 'federal', 'policy', 'regulation', 'subsidy', 'incentive',
        'clean energy', 'carbon neutral', 'net zero', 'climate', 'ESG',
        'IRA', 'inflation reduction act', 'infrastructure', 'CHIPS act',
        'national defense', 'strategic', 'critical', 'export control',
        
        # ğŸŒŸ ì—…ì¢…ë³„ íŠ¹ìˆ˜ ì´ë²¤íŠ¸
        'uranium price', 'spot uranium', 'nuclear renaissance', 'reactor restart',
        'AI boom', 'generative AI', 'ChatGPT', 'machine learning', 'GPU demand',
        'space economy', 'NewSpace', 'satellite internet', 'lunar mission', 'mars'
    ]
    
    # ğŸ”¥ ê¸°ì¡´ RKLB íŠ¹í™” ê³ ì˜í–¥ í‚¤ì›Œë“œ (ê·¸ëŒ€ë¡œ ìœ ì§€)
    high_impact_keywords = [
        # ê¸°ë³¸ ê³ ì˜í–¥ í‚¤ì›Œë“œ
        'earnings beat', 'earnings miss', 'guidance raise', 'guidance cut',
        'FDA approval', 'NRC approval', 'patent approval', 'breakthrough', 'acquisition',
        'merger', 'CEO resign', 'lawsuit', 'investigation', 'bankruptcy',
        
        # CCJ (ì¹´ë©”ì½”) ê³ ì˜í–¥ í‚¤ì›Œë“œ
        'uranium price surge', 'uranium shortage', 'mine restart', 'production halt',
        'Kazakhstan disruption', 'nuclear fuel shortage', 'utility contract',
        'long term agreement', 'reactor restart', 'nuclear policy',
        'uranium stockpile', 'enrichment capacity', 'fuel cycle disruption',
        
        # BWXT ê³ ì˜í–¥ í‚¤ì›Œë“œ
        'SMR approval', 'reactor design approval', 'navy contract award',
        'DOE funding', 'nuclear fuel contract', 'HALEU production',
        'microreactor deployment', 'nuclear export license', 'fuel fabrication',
        'nuclear accident', 'safety incident', 'regulatory violation',
        
        # VRT (ë²„í‹°ë¸Œ) ê³ ì˜í–¥ í‚¤ì›Œë“œ
        'data center boom', 'AI infrastructure demand', 'hyperscale expansion',
        'cooling technology breakthrough', 'power outage', 'cooling failure',
        'Microsoft partnership', 'Amazon contract', 'Google deal',
        'liquid cooling adoption', 'sustainability mandate', 'energy crisis',
        
        # RKLB (ë¡œì¼“ë©) ê³ ì˜í–¥ í‚¤ì›Œë“œ
        'launch success', 'launch failure', 'NASA contract', 'defense contract',
        'space force contract', 'satellite deployment', 'constellation launch',
        'rocket explosion', 'pad accident', 'mission failure',
        'reusability breakthrough', 'cost reduction', 'launch frequency',
        'competitor selection', 'SpaceX competition', 'market share gain',
        
        # ì—…ì¢… ê³µí†µ ê³ ì˜í–¥ í‚¤ì›Œë“œ
        'government contract', 'partnership announcement', 'technology breakthrough',
        'capacity expansion', 'facility closure', 'production increase',
        'supply disruption', 'raw material shortage', 'price increase',
        'demand surge', 'market consolidation', 'regulatory change'
    ]
    
    # ğŸ”¥ğŸ”¥ NEW: ìë™ ê²½ì œ ìº˜ë¦°ë” ê¸°ë°˜ ë™ì  í‚¤ì›Œë“œ ì¶”ê°€ ğŸ”¥ğŸ”¥
    if ECONOMIC_CALENDAR_AVAILABLE:
        try:
            # ìë™ ìº˜ë¦°ë”ì—ì„œ ê²½ì œ ì´ë²¤íŠ¸ í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°
            updater = auto_economic_calendar.AutoEconomicCalendarUpdater()
            calendar_data = updater.update_calendar_if_needed()
            
            if calendar_data:
                # ë‹¤ê°€ì˜¤ëŠ” ê²½ì œ ì´ë²¤íŠ¸ í‚¤ì›Œë“œ ì¶”ê°€
                upcoming_events = auto_economic_calendar.get_upcoming_events_from_calendar(calendar_data, days_ahead=7)
                
                economic_keywords = []
                high_impact_economic_keywords = []
                
                for event in upcoming_events:
                    # ì´ë²¤íŠ¸ë³„ í‚¤ì›Œë“œ ì¶”ê°€
                    economic_keywords.extend(event.get("keywords", []))
                    
                    # ì„ë°•í•œ ê³ ì¤‘ìš” ì´ë²¤íŠ¸ëŠ” ê³ ì˜í–¥ í‚¤ì›Œë“œë¡œ ìŠ¹ê²© (3ì¼ ì´ë‚´)
                    if event["days_ahead"] <= 3 and event["importance"] == "high":
                        high_impact_economic_keywords.extend(event.get("keywords", []))
                
                # ë™ì  ê²€ìƒ‰ì–´ë„ í‚¤ì›Œë“œë¡œ ì¶”ê°€
                dynamic_terms = auto_economic_calendar.generate_dynamic_search_terms()
                for term in dynamic_terms:
                    term_keywords = [word.lower() for word in term.split() if len(word) > 2]
                    economic_keywords.extend(term_keywords)
                
                # ğŸ”¥ ê¸°ì¡´ RKLB í‚¤ì›Œë“œì™€ ê²½ì œ í‚¤ì›Œë“œ ë³‘í•©
                impact_keywords.extend(economic_keywords)
                high_impact_keywords.extend(high_impact_economic_keywords)
                
                # ì¤‘ë³µ ì œê±°
                impact_keywords = list(set(impact_keywords))
                high_impact_keywords = list(set(high_impact_keywords))
                
                logger.info(f"ğŸ¤– RKLB íŠ¹í™” + ê²½ì œ ìº˜ë¦°ë” í‚¤ì›Œë“œ í†µí•© ì™„ë£Œ")
                logger.info(f"   ê¸°ì¡´ RKLB í‚¤ì›Œë“œ ìœ ì§€ + ê²½ì œ í‚¤ì›Œë“œ {len(economic_keywords)}ê°œ ì¶”ê°€")
                logger.info(f"   ì´ ê¸°ë³¸ í‚¤ì›Œë“œ: {len(impact_keywords)}ê°œ")
                logger.info(f"   ì´ ê³ ì˜í–¥ í‚¤ì›Œë“œ: {len(high_impact_keywords)}ê°œ")
                
                # ì„ë°•í•œ ê³ ì˜í–¥ ì´ë²¤íŠ¸ ì•Œë¦¼
                for event in upcoming_events:
                    if event["days_ahead"] <= 3 and event["importance"] == "high":
                        logger.info(f"ğŸ”¥ RKLB í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë ¨ ê²½ì œ ì´ë²¤íŠ¸ ì„ë°•: {event['event']} ({event['days_ahead']}ì¼ í›„)")
                
            else:
                logger.warning("âš ï¸ ìë™ ìº˜ë¦°ë” ë¡œë“œ ì‹¤íŒ¨ - RKLB ê¸°ë³¸ í‚¤ì›Œë“œë§Œ ì‚¬ìš©")
                
        except Exception as e:
            logger.error(f"âŒ ê²½ì œ ìº˜ë¦°ë” í‚¤ì›Œë“œ í†µí•© ì˜¤ë¥˜: {e} - RKLB ê¸°ë³¸ í‚¤ì›Œë“œë§Œ ì‚¬ìš©")
    else:
        logger.info("ğŸ“Š RKLB íŠ¹í™” ê¸°ë³¸ í‚¤ì›Œë“œ ì‹œìŠ¤í…œ ì‚¬ìš© (ê²½ì œ ìº˜ë¦°ë” ì—†ìŒ)")
    
    return impact_keywords, high_impact_keywords

def calculate_relevance_score(headline, summary, impact_keywords, high_impact_keywords):
    """RKLB íŠ¹í™” + ê²½ì œ ì´ë²¤íŠ¸ ë³´ë„ˆìŠ¤ ê´€ë ¨ë„ ì ìˆ˜ ê³„ì‚°"""

    if ECONOMIC_CALENDAR_AVAILABLE:
        try:
            # ìë™ ìº˜ë¦°ë” ê¸°ë°˜ í–¥ìƒëœ ê´€ë ¨ë„ ê³„ì‚°
            return auto_economic_calendar.calculate_enhanced_relevance_score(
                headline, summary, impact_keywords, high_impact_keywords
            )
        except Exception as e:
            logger.error(f"âŒ í–¥ìƒëœ ê´€ë ¨ë„ ê³„ì‚° ì˜¤ë¥˜: {e} - ê¸°ë³¸ ê³„ì‚° ì‚¬ìš©")
  
    try:
        content_text = f"{headline} {summary}".lower()
        headline_lower = headline.lower()
        
        # 1. ê¸°ë³¸ í‚¤ì›Œë“œ ì ìˆ˜
        basic_score = sum(1 for keyword in impact_keywords if keyword in content_text)
        
        # 2. ê³ ì˜í–¥ í‚¤ì›Œë“œ ì ìˆ˜ (2ë°° ê°€ì¤‘ì¹˜)
        high_impact_score = sum(2 for keyword in high_impact_keywords if keyword in content_text)
        
        # 3. ì œëª©ì— í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì¶”ê°€ ì ìˆ˜ (ì œëª©ì´ ë” ì¤‘ìš”)
        headline_bonus = sum(1 for keyword in impact_keywords if keyword in headline_lower)
        
        # 4. ê³ ì˜í–¥ í‚¤ì›Œë“œê°€ ì œëª©ì— ìˆìœ¼ë©´ ì¶”ê°€ ë³´ë„ˆìŠ¤
        headline_high_impact_bonus = sum(2 for keyword in high_impact_keywords if keyword in headline_lower)
        
        # 5. í¬íŠ¸í´ë¦¬ì˜¤ íŠ¹í™” ë³´ë„ˆìŠ¤
        portfolio_bonus = 0
        
        # CCJ ê´€ë ¨ íŠ¹í™” ë³´ë„ˆìŠ¤
        ccj_terms = ['uranium', 'cameco', 'nuclear fuel', 'mining', 'yellowcake']
        if any(term in content_text for term in ccj_terms):
            portfolio_bonus += 1
            
        # BWXT ê´€ë ¨ íŠ¹í™” ë³´ë„ˆìŠ¤
        bwxt_terms = ['BWX', 'BWXT', 'naval reactor', 'SMR', 'nuclear component']
        if any(term in content_text for term in bwxt_terms):
            portfolio_bonus += 1
            
        # VRT ê´€ë ¨ íŠ¹í™” ë³´ë„ˆìŠ¤
        vrt_terms = ['vertiv', 'data center', 'cooling', 'infrastructure', 'AI']
        if any(term in content_text for term in vrt_terms):
            portfolio_bonus += 1
            
        # RKLB ê´€ë ¨ íŠ¹í™” ë³´ë„ˆìŠ¤
        rklb_terms = ['rocket lab', 'electron', 'neutron', 'launch', 'satellite']
        if any(term in content_text for term in rklb_terms):
            portfolio_bonus += 1
        
        total_score = basic_score + high_impact_score + headline_bonus + headline_high_impact_bonus + portfolio_bonus
        
        return total_score
        
    except Exception as e:
        logger.error(f"ê´€ë ¨ë„ ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
        return 0

# Finnhub ê¸°ë°˜ ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜ (RKLB í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”)
def get_us_stock_news_finnhub(ticker, days_back=3, max_retries=3):
    """Finnhub APIë¥¼ í†µí•œ ë¯¸êµ­ ì£¼ì‹ ë‰´ìŠ¤ ìˆ˜ì§‘ (RKLB í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”)"""
    for attempt in range(max_retries):
        try:
            load_dotenv()
            finnhub_key = os.getenv("FINNHUB_API_KEY")
            if not finnhub_key:
                logger.error("FINNHUB_API_KEYê°€ .env íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤")
                return []

            today = datetime.now()
            from_date = (today - timedelta(days=days_back)).strftime("%Y-%m-%d")
            to_date = today.strftime("%Y-%m-%d")

            url = f"https://finnhub.io/api/v1/company-news"
            params = {
                "symbol": ticker.upper(), 
                "from": from_date, 
                "to": to_date, 
                "token": finnhub_key
            }
            
            logger.info(f"ğŸ“° {ticker} ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
            response = requests.get(url, params=params, timeout=15)
            
            if response.status_code == 429:
                wait_time = 60 * (attempt + 1)
                logger.warning(f"â³ Finnhub API í•œë„ ë„ë‹¬ - {wait_time}ì´ˆ ëŒ€ê¸°")
                time.sleep(wait_time)
                continue
            elif response.status_code == 401:
                logger.error(f"âŒ API í‚¤ ì¸ì¦ ì‹¤íŒ¨")
                return []
            elif response.status_code != 200:
                logger.error(f"âŒ API ì˜¤ë¥˜: {response.status_code}")
                return []
                
            data = response.json()

            if not isinstance(data, list):
                logger.warning(f"âš ï¸ {ticker}: ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì‘ë‹µ í˜•íƒœ")
                return []

            if len(data) == 0:
                logger.info(f"ğŸ“° {ticker}: í•´ë‹¹ ê¸°ê°„ì— ë‰´ìŠ¤ ì—†ìŒ")
                return []

            # ğŸ”¥ RKLB í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” í‚¤ì›Œë“œ ì‹œìŠ¤í…œ ì ìš©
            impact_keywords, high_impact_keywords = get_impact_keywords()
            
            articles = []
            for item in data:
                if not isinstance(item, dict) or "headline" not in item or "datetime" not in item:
                    continue
                    
                dt = datetime.fromtimestamp(item["datetime"])
                if dt < datetime.now() - timedelta(days=days_back):
                    continue
                    
                headline = item["headline"]
                summary = item.get("summary", "")
                source = item.get("source", "Unknown")
                date_str = dt.strftime("%Y-%m-%d %H:%M")

                # ğŸ”¥ RKLB í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” ê´€ë ¨ë„ ì ìˆ˜ ê³„ì‚°
                relevance_score = calculate_relevance_score(headline, summary, impact_keywords, high_impact_keywords)

                # ê´€ë ¨ë„ê°€ 0ì¸ ë‰´ìŠ¤ë„ í¬í•¨í•˜ë˜ ìš°ì„ ìˆœìœ„ì—ì„œ ë°€ë¦¼
                articles.append({
                    "title": headline,
                    "snippet": summary[:150] if summary else headline[:150],
                    "source": source,
                    "date": date_str,
                    "relevance_score": relevance_score
                })

            # ê´€ë ¨ë„ ìˆœìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ì ìˆ˜ë¶€í„°)
            articles.sort(key=lambda x: x['relevance_score'], reverse=True)
            selected_articles = articles[:5]
            
            # ê´€ë ¨ë„ ì ìˆ˜ ë¡œê¹…
            if selected_articles:
                avg_relevance = sum(a['relevance_score'] for a in selected_articles) / len(selected_articles)
                max_relevance = max(a['relevance_score'] for a in selected_articles)
                logger.info(f"âœ… {ticker}: {len(selected_articles)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ (ê´€ë ¨ë„: í‰ê·  {avg_relevance:.1f}, ìµœê³  {max_relevance})")
            else:
                logger.info(f"âœ… {ticker}: {len(selected_articles)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")
            
            return selected_articles
            
        except requests.exceptions.RequestException as e:
            logger.error(f"ğŸŒ {ticker} ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ (ì‹œë„ {attempt+1}): {e}")
            if attempt < max_retries - 1:
                time.sleep(5)
        except Exception as e:
            logger.error(f"âŒ {ticker} ë‰´ìŠ¤ ìˆ˜ì§‘ ì˜¤ë¥˜ (ì‹œë„ {attempt+1}): {e}")
            if attempt < max_retries - 1:
                time.sleep(2)
    
    logger.warning(f"âš ï¸ {ticker} ë‰´ìŠ¤ ìˆ˜ì§‘ ìµœì¢… ì‹¤íŒ¨")
    return []

# RKLB í¬íŠ¸í´ë¦¬ì˜¤ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì „ì²´ ë¶„ì„ í•¨ìˆ˜
def analyze_us_stocks_news(stocks_list):
    """RKLB í¬íŠ¸í´ë¦¬ì˜¤ ë¯¸êµ­ ì£¼ì‹ë“¤ì˜ ë‰´ìŠ¤ë¥¼ ì¢…í•© ë¶„ì„"""
    try:
        if not stocks_list:
            logger.warning("ğŸ“° ë¶„ì„ ëŒ€ìƒ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤")
            return {}

        # ìºì‹œ í™•ì¸
        cache_key = create_stocks_hash(stocks_list)
        cached_result = get_cached_gpt_analysis(cache_key, cache_minutes=240)
        if cached_result:
            logger.info("ğŸ“° ìºì‹œëœ ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ ì‚¬ìš©")
            return cached_result

        logger.info(f"ğŸ“° RKLB í¬íŠ¸í´ë¦¬ì˜¤ ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘ - ëŒ€ìƒ: {len(stocks_list)}ê°œ ì¢…ëª©")

        # ê° ì¢…ëª©ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘
        news_data = {"stocks": {}}
        total_articles = 0
        
        for stock in stocks_list:
            ticker = stock.get("ticker")
            company_name = stock.get("company_name")
            
            if not ticker or not company_name:
                logger.warning(f"âš ï¸ ì˜ëª»ëœ ì¢…ëª© ì •ë³´: {stock}")
                continue

            articles = get_us_stock_news_finnhub(ticker, days_back=2)  # 2ì¼ê°„ ë‰´ìŠ¤
            
            if not articles:
                logger.info(f"ğŸ“° {company_name}({ticker}): ë‰´ìŠ¤ ì—†ìŒ")
                continue

            news_data["stocks"][company_name] = {
                "stock_code": ticker,
                "ticker": ticker,
                "articles": [{
                    "title": a['title'],
                    "snippet": a['snippet'],
                    "source": a['source'],
                    "date": a['date'],
                    "relevance_score": a.get('relevance_score', 0)  # ê´€ë ¨ë„ ì ìˆ˜ í¬í•¨
                } for a in articles[:3]]  # ìƒìœ„ 3ê°œë§Œ
            }
            
            total_articles += len(articles)

        if not news_data["stocks"]:
            logger.info("ğŸ“° ë¶„ì„í•  ë‰´ìŠ¤ê°€ ì—†ì–´ì„œ ë¹ˆ ê²°ê³¼ ë°˜í™˜")
            empty_result = {"stocks": {}}
            cache_gpt_analysis(cache_key, empty_result)
            return empty_result

        logger.info(f"ğŸ“Š ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ: {len(news_data['stocks'])}ê°œ ì¢…ëª©, {total_articles}ê°œ ë‰´ìŠ¤")

        # OpenAI GPTë¡œ ë‰´ìŠ¤ ë¶„ì„
        logger.info("ğŸ¤– OpenAI GPTë¡œ RKLB í¬íŠ¸í´ë¦¬ì˜¤ ë‰´ìŠ¤ ê°ì • ë¶„ì„ ì‹œì‘")
        
        load_dotenv()
        openai_key = os.getenv("OPENAI_API_KEY")
        if not openai_key:
            logger.error("OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤")
            return news_data

        client = OpenAI(api_key=openai_key)

        # ğŸ”¥ RKLB í¬íŠ¸í´ë¦¬ì˜¤ íŠ¹í™” í”„ë¡¬í”„íŠ¸
        system_prompt = """You are a professional financial analyst specializing in US stock market news analysis for the RKLB Portfolio.

Analyze the impact of news articles on stock prices for the provided companies in our focused portfolio.

For each company, provide your analysis in the following JSON format:
{
  "analyses": [
    {
      "stock_name": "Company Name",
      "decision": "POSITIVE" or "NEGATIVE" or "NEUTRAL",
      "percentage": 75,
      "reason": "Brief explanation of your decision"
    }
  ]
}

Guidelines:
- POSITIVE: News likely to increase stock price (earnings beat, new contracts, partnerships, breakthroughs, etc.)
- NEGATIVE: News likely to decrease stock price (earnings miss, lawsuits, downgrades, setbacks, etc.)
- NEUTRAL: No significant impact expected
- Percentage: 1-100 for impact strength, 0 for neutral
- Focus on recent news and actual business impact

Industry-Specific Analysis Focus:
* Uranium Mining (CCJ - Cameco Corp): 
  - Uranium spot prices, mine operations, utility contracts, nuclear policy changes
  - Kazakhstan geopolitical risks, production capacity, long-term fuel agreements
  - Nuclear renaissance trends, reactor restarts, new nuclear construction
  
* Nuclear Technology (BWXT - BWX Technologies): 
  - Naval reactor contracts, SMR developments, nuclear fuel services
  - DOE/NNSA funding, regulatory approvals, HALEU production capabilities
  - Defense contracts, nuclear component manufacturing, safety incidents
  
* Data Center Infrastructure (VRT - Vertiv Holdings): 
  - AI boom impact, hyperscale data center demand, cooling technology advances
  - Power infrastructure needs, sustainability mandates, efficiency breakthroughs
  - Major cloud provider partnerships (Microsoft, Amazon, Google contracts)
  
* Space Technology (RKLB - Rocket Lab USA): 
  - Launch successes/failures, satellite deployment missions, NASA partnerships
  - Defense/Space Force contracts, commercial space market developments
  - Competition with SpaceX, reusability achievements, cost reduction milestones

Priority Factors:
- Weight earnings reports, regulatory approvals, major contracts, and commodity prices heavily
- Consider government policies affecting nuclear energy, space industry, and AI infrastructure
- Pay special attention to supply chain disruptions, geopolitical risks, and technology breakthroughs
- Evaluate competitive positioning within each specialized industry sector
- Consider ESG factors and sustainability trends impacting energy and technology sectors"""

        try:
            # ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë” ê°„ê²°í•˜ê²Œ ì •ë¦¬ (ê´€ë ¨ë„ ì ìˆ˜ í¬í•¨)
            simplified_news = {}
            for company, data in news_data["stocks"].items():
                simplified_news[company] = {
                    "ticker": data["ticker"],
                    "recent_news": [
                        f"â€¢ [Score:{article.get('relevance_score', 0)}] {article['title']} - {article['snippet'][:100]}..."
                        for article in data["articles"]
                    ]
                }

            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"Analyze the market impact of these news for our RKLB Portfolio (relevance scores indicate keyword relevance to our portfolio themes):\n\n{json.dumps(simplified_news, ensure_ascii=False, indent=2)}"}
            ]

            response = client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                temperature=0.1,
                max_tokens=1500,
                timeout=30
            )

            gpt_response = response.choices[0].message.content.strip()
            logger.info(f"ğŸ¤– GPT ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ ({len(gpt_response)} chars)")

            # JSON íŒŒì‹±
            try:
                # JSON ë¸”ë¡ ì¶”ì¶œ
                if '```json' in gpt_response:
                    json_start = gpt_response.find('{', gpt_response.find('```json'))
                    json_end = gpt_response.rfind('}', 0, gpt_response.rfind('```')) + 1
                    json_str = gpt_response[json_start:json_end]
                elif gpt_response.strip().startswith('{'):
                    json_str = gpt_response.strip()
                else:
                    json_start = gpt_response.find('{')
                    json_end = gpt_response.rfind('}') + 1
                    if json_start != -1 and json_end > json_start:
                        json_str = gpt_response[json_start:json_end]
                    else:
                        raise ValueError("JSON í˜•íƒœë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")

                result = json.loads(json_str)
                
                if "analyses" not in result:
                    logger.error("GPT ì‘ë‹µì— 'analyses' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
                    raise ValueError("Invalid response format")

            except (json.JSONDecodeError, ValueError) as e:
                logger.error(f"âŒ GPT ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                logger.error(f"ì›ë³¸ ì‘ë‹µ (ì²˜ìŒ 500ì): {gpt_response[:500]}")
                
                # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì¤‘ë¦½ìœ¼ë¡œ ì²˜ë¦¬
                result = {"analyses": []}
                for company_name in news_data["stocks"].keys():
                    result["analyses"].append({
                        "stock_name": company_name,
                        "decision": "NEUTRAL",
                        "percentage": 0,
                        "reason": "GPT ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨ë¡œ ì¤‘ë¦½ ì²˜ë¦¬"
                    })

            # ë¶„ì„ ê²°ê³¼ë¥¼ news_dataì— í†µí•©
            for analysis in result.get("analyses", []):
                stock_name = analysis.get("stock_name", "")
                if stock_name in news_data["stocks"]:
                    news_data["stocks"][stock_name]["analysis"] = {
                        "decision": analysis.get("decision", "NEUTRAL"),
                        "percentage": analysis.get("percentage", 0),
                        "reason": analysis.get("reason", "ë¶„ì„ ê²°ê³¼ ì—†ìŒ")
                    }

            # ê²°ê³¼ ë¡œê¹…
            logger.info("ğŸ“Š RKLB í¬íŠ¸í´ë¦¬ì˜¤ ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼:")
            for analysis in result.get("analyses", []):
                name = analysis.get("stock_name", "Unknown")
                decision = analysis.get("decision", "NEUTRAL")
                percentage = analysis.get("percentage", 0)
                reason = analysis.get("reason", "")
                
                # í¬íŠ¸í´ë¦¬ì˜¤ë³„ ì´ëª¨ì§€
                emoji_map = {
                    "Cameco Corp": "âš›ï¸",
                    "BWX Technologies Inc": "ğŸ­", 
                    "Vertiv Holdings Co": "â„ï¸",
                    "Rocket Lab USA Inc": "ğŸš€"
                }
                stock_emoji = emoji_map.get(name, {"POSITIVE": "ğŸ“ˆ", "NEGATIVE": "ğŸ“‰", "NEUTRAL": "â–"}.get(decision, "â“"))
                
                logger.info(f"  {stock_emoji} {name}: {decision} ({percentage}%) - {reason}")

            # ìºì‹œ ì €ì¥
            cache_gpt_analysis(cache_key, news_data)
            logger.info("âœ… RKLB í¬íŠ¸í´ë¦¬ì˜¤ ë‰´ìŠ¤ ë¶„ì„ ì™„ë£Œ ë° ìºì‹œ ì €ì¥")
            
            return news_data

        except Exception as e:
            logger.error(f"âŒ OpenAI API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            # OpenAI ì˜¤ë¥˜ ì‹œì—ë„ ë‰´ìŠ¤ ë°ì´í„°ëŠ” ë°˜í™˜
            return news_data

    except Exception as e:
        logger.error(f"âŒ RKLB í¬íŠ¸í´ë¦¬ì˜¤ ì „ì²´ ë‰´ìŠ¤ ë¶„ì„ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return {}

# ğŸ§ª RKLB í¬íŠ¸í´ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ìš©
if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    
    # ğŸ¯ RKLB í¬íŠ¸í´ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì¢…ëª© (CCJ+BWXT+VRT+RKLB)
    test_stocks = [
        {"ticker": "CCJ", "company_name": "Cameco Corp"},
        {"ticker": "BWXT", "company_name": "BWX Technologies Inc"},
        {"ticker": "VRT", "company_name": "Vertiv Holdings Co"},
        {"ticker": "RKLB", "company_name": "Rocket Lab USA Inc"}
    ]
    
    print("ğŸš€ RKLB í¬íŠ¸í´ë¦¬ì˜¤ ë‰´ìŠ¤ ë¶„ì„ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("ğŸ“‹ ëŒ€ìƒ ì¢…ëª©: CCJ(ìš°ë¼ëŠ„) + BWXT(ì›ìë¡œ) + VRT(ë°ì´í„°ì„¼í„°) + RKLB(ìš°ì£¼í•­ê³µ)")
    print("=" * 80)
    
    result = analyze_us_stocks_news(test_stocks)
    
    print(f"\nğŸ“Š RKLB í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ ê²°ê³¼:")
    print("=" * 80)
    
    if result.get("stocks"):
        # í¬íŠ¸í´ë¦¬ì˜¤ë³„ í…Œë§ˆ êµ¬ë¶„
        themes = {
            "ì›ì „ ë…ì  ì²´ì¸ (60%)": ["Cameco Corp", "BWX Technologies Inc"],
            "ë¯¸ë˜ ê¸°ìˆ  (40%)": ["Vertiv Holdings Co", "Rocket Lab USA Inc"]
        }
        
        for theme_name, companies in themes.items():
            print(f"\nğŸ¯ {theme_name}")
            print("-" * 50)
            
            for company in companies:
                if company in result["stocks"]:
                    data = result["stocks"][company]
                    
                    # íšŒì‚¬ë³„ ì´ëª¨ì§€
                    company_emoji = {
                        "Cameco Corp": "âš›ï¸", 
                        "BWX Technologies Inc": "ğŸ­",
                        "Vertiv Holdings Co": "â„ï¸", 
                        "Rocket Lab USA Inc": "ğŸš€"
                    }.get(company, "ğŸ¢")
                    
                    print(f"\n{company_emoji} {company} ({data['ticker']}):")
                    
                    # ë‰´ìŠ¤ ì¶œë ¥ (ê´€ë ¨ë„ ì ìˆ˜ í¬í•¨)
                    print("  ğŸ“° ì£¼ìš” ë‰´ìŠ¤:")
                    if data.get("articles"):
                        for i, article in enumerate(data["articles"], 1):
                            relevance = article.get('relevance_score', 0)
                            print(f"    [{i}] [ê´€ë ¨ë„:{relevance}ì ] {article['title'][:70]}...")
                            print(f"        â””â”€ {article['source']} | {article['date']}")
                    else:
                        print("    ğŸ“­ ìµœê·¼ ë‰´ìŠ¤ ì—†ìŒ")
                    
                    # ë¶„ì„ ê²°ê³¼ ì¶œë ¥
                    if "analysis" in data:
                        analysis = data["analysis"]
                        decision_emoji = {"POSITIVE": "ğŸ“ˆ", "NEGATIVE": "ğŸ“‰", "NEUTRAL": "â–"}.get(analysis["decision"], "â“")
                        print(f"  {decision_emoji} íˆ¬ì ì˜í–¥: {analysis['decision']} ({analysis['percentage']}%)")
                        print(f"  ğŸ’­ ë¶„ì„ ê·¼ê±°: {analysis['reason']}")
                    else:
                        print("  âš ï¸ ë¶„ì„ ê²°ê³¼ ì—†ìŒ")
                else:
                    print(f"\nğŸ¢ {company}: ğŸ“­ ë‰´ìŠ¤ ì—†ìŒ")
        
        # í¬íŠ¸í´ë¦¬ì˜¤ ì¢…í•© ìš”ì•½
        print(f"\nğŸ“ˆ í¬íŠ¸í´ë¦¬ì˜¤ ì¢…í•© ìš”ì•½:")
        print("=" * 50)
        
        positive_count = sum(1 for data in result["stocks"].values() 
                           if data.get("analysis", {}).get("decision") == "POSITIVE")
        negative_count = sum(1 for data in result["stocks"].values() 
                           if data.get("analysis", {}).get("decision") == "NEGATIVE")
        neutral_count = sum(1 for data in result["stocks"].values() 
                          if data.get("analysis", {}).get("decision") == "NEUTRAL")
        
        total_analyzed = positive_count + negative_count + neutral_count
        
        if total_analyzed > 0:
            print(f"ğŸ“ˆ ê¸ì •ì : {positive_count}ê°œ ì¢…ëª© ({positive_count/total_analyzed*100:.1f}%)")
            print(f"ğŸ“‰ ë¶€ì •ì : {negative_count}ê°œ ì¢…ëª© ({negative_count/total_analyzed*100:.1f}%)")
            print(f"â– ì¤‘ë¦½ì : {neutral_count}ê°œ ì¢…ëª© ({neutral_count/total_analyzed*100:.1f}%)")
            
            # ì „ì²´ì ì¸ í¬íŠ¸í´ë¦¬ì˜¤ ê±´ê°•ë„
            if positive_count > negative_count:
                portfolio_health = "ğŸŸ¢ ì–‘í˜¸"
            elif positive_count < negative_count:
                portfolio_health = "ğŸ”´ ì£¼ì˜"
            else:
                portfolio_health = "ğŸŸ¡ ë³´í†µ"
                
            print(f"ğŸ¯ í¬íŠ¸í´ë¦¬ì˜¤ ê±´ê°•ë„: {portfolio_health}")
        else:
            print("ğŸ“­ ë¶„ì„ ê°€ëŠ¥í•œ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            
    else:
        print("âŒ ë‰´ìŠ¤ ë˜ëŠ” ë¶„ì„ ê²°ê³¼ ì—†ìŒ")
        
    # RKLB í¬íŠ¸í´ë¦¬ì˜¤ íŠ¹í™” í‚¤ì›Œë“œ í†µê³„ ì¶œë ¥
    print(f"\nğŸ“ˆ RKLB í¬íŠ¸í´ë¦¬ì˜¤ í‚¤ì›Œë“œ ì‹œìŠ¤í…œ í†µê³„:")
    print("=" * 50)
    
    impact_keywords, high_impact_keywords = get_impact_keywords()
    print(f"ğŸ“ ê¸°ë³¸ í‚¤ì›Œë“œ: {len(impact_keywords)}ê°œ")
    print(f"âš¡ ê³ ì˜í–¥ í‚¤ì›Œë“œ: {len(high_impact_keywords)}ê°œ")
    print(f"ğŸ“Š ì´ í‚¤ì›Œë“œ: {len(impact_keywords) + len(high_impact_keywords)}ê°œ")
    
    # í¬íŠ¸í´ë¦¬ì˜¤ë³„ íŠ¹í™” í‚¤ì›Œë“œ ì¹´ìš´íŠ¸
    ccj_keywords = [k for k in impact_keywords if any(term in k for term in ['uranium', 'cameco', 'nuclear fuel', 'mining', 'yellowcake'])]
    bwxt_keywords = [k for k in impact_keywords if any(term in k for term in ['reactor', 'BWXT', 'SMR', 'naval', 'nuclear component'])]
    vrt_keywords = [k for k in impact_keywords if any(term in k for term in ['data center', 'cooling', 'vertiv', 'infrastructure', 'AI'])]
    rklb_keywords = [k for k in impact_keywords if any(term in k for term in ['rocket', 'space', 'satellite', 'launch', 'electron'])]
    
    print(f"\nğŸ¯ ì¢…ëª©ë³„ íŠ¹í™” í‚¤ì›Œë“œ ë¶„í¬:")
    print(f"  âš›ï¸ ìš°ë¼ëŠ„(CCJ): {len(ccj_keywords)}ê°œ")
    print(f"  ğŸ­ ì›ìë¡œ(BWXT): {len(bwxt_keywords)}ê°œ") 
    print(f"  â„ï¸ ë°ì´í„°ì„¼í„°(VRT): {len(vrt_keywords)}ê°œ")
    print(f"  ğŸš€ ìš°ì£¼í•­ê³µ(RKLB): {len(rklb_keywords)}ê°œ")
    
    print(f"\nğŸ‰ RKLB í¬íŠ¸í´ë¦¬ì˜¤ ë‰´ìŠ¤ ë¶„ì„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 80)